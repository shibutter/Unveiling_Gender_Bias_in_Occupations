{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fighting_words as fw\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt = pd.read_csv('data/data_gpt_processed.csv', sep=',', encoding='latin1')\n",
    "df_llama = pd.read_csv('data/data_llama_processed.csv', sep=',', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filepath, sep=';'):\n",
    "    return pd.read_csv(filepath, sep=sep, encoding='ISO-8859-1')\n",
    "\n",
    "def process_and_save(data_path, prefix):\n",
    "    df = pd.read_csv(data_path, sep=';')\n",
    "    verbs, adjectives = fw.get_fighting_words(df)\n",
    "    fw.save_to_csv(verbs, f'{prefix}_vrb.csv')\n",
    "    fw.save_to_csv(adjectives, f'{prefix}_adj.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Solely adjectives and verbs\n",
    "'''\n",
    "\n",
    "# Dictionary of dataset paths and their prefixes\n",
    "datasets = {\n",
    "    'data/df_gpt.csv': 'gpt',\n",
    "    'data/df_llama.csv': 'llama'\n",
    "}\n",
    "\n",
    "nlp = spacy.load('nl_core_news_lg')\n",
    "for path, prefix in datasets.items():\n",
    "    process_and_save(path, prefix, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size is 653\n",
      "Comparing language...\n",
      "Vocab size is 262\n",
      "Comparing language...\n",
      "Vocab size is 661\n",
      "Comparing language...\n",
      "Vocab size is 255\n",
      "Comparing language...\n",
      "Vocab size is 492\n",
      "Comparing language...\n",
      "Vocab size is 236\n",
      "Comparing language...\n",
      "Vocab size is 610\n",
      "Comparing language...\n",
      "Vocab size is 229\n",
      "Comparing language...\n",
      "Vocab size is 869\n",
      "Comparing language...\n",
      "Vocab size is 305\n",
      "Comparing language...\n",
      "Vocab size is 637\n",
      "Comparing language...\n",
      "Vocab size is 244\n",
      "Comparing language...\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Genre\n",
    "'''\n",
    "\n",
    "def process_datasets(datasets, nlp):\n",
    "    \"\"\"Process each dataset for different genres and save results.\"\"\"\n",
    "    for name, df in datasets.items():\n",
    "        grouped_datasets = {genre: group for genre, group in df.groupby('Genre')}\n",
    "        for genre in ['thriller', 'literaire fictie', 'romantisch']:\n",
    "            df_genre = grouped_datasets.get(genre)\n",
    "            if df_genre is not None:\n",
    "                fw_adj, fw_vrb = fw.get_fighting_words(df_genre, nlp)\n",
    "                fw.save_to_csv(fw_adj, f'{name}_{genre}_adj.csv')\n",
    "                fw.save_to_csv(fw_vrb, f'{name}_{genre}_vrb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Prompt\n",
    "'''\n",
    "\n",
    "def process_datasets(datasets):\n",
    "    \"\"\"Process each dataset for specified prompt types and save results.\"\"\"\n",
    "    for name, df in datasets.items():\n",
    "        grouped_datasets = {prompt: group for prompt, group in df.groupby('Prompt_type')}\n",
    "        for prompt in ['instructional', 'completion', 'question-answer', 'contextual']:\n",
    "            process_prompt(grouped_datasets, name, prompt)\n",
    "\n",
    "def process_prompt(grouped_datasets, dataset_name, prompt):\n",
    "    \"\"\"Process and save data for a specific prompt type.\"\"\"\n",
    "    nlp = spacy.load('nl_core_news_lg')\n",
    "    df_prompt = grouped_datasets.get(prompt)\n",
    "    if df_prompt is not None:\n",
    "        fw_adj, fw_vrb = fw.get_fighting_words(df_prompt , nlp)\n",
    "        save_to_csv(fw_adj, f'{dataset_name}_{prompt}_adj.csv')\n",
    "        save_to_csv(fw_vrb, f'{dataset_name}_{prompt}_vrb.csv')\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    \"\"\"Save data to CSV file in a specified directory.\"\"\"\n",
    "    save_path = 'fw_data/'\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    full_path = os.path.join(save_path, filename)\n",
    "    with open(full_path, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for item, zscore in data:\n",
    "            writer.writerow([item, zscore])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
